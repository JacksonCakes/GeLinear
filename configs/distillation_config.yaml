data:
  dataset_path: "/home/jackson/LLaMA-Factory/notebook/cache/allenai___tulu-3-sft-mixture"
  tokenizer_path: "/tmp2/share_data/google-gemma-9b-it"
  split_ratio: 0.1
  subset: "train[:400000]"
  remove_columns_from_train: true

model:
  model_path: "/tmp2/share_data/google-gemma-9b-it/"
  device: "cuda:0"
  checkpoint_dir: "./checkpoints_0to1"

training:
  lr: 1e-4
  num_epochs: 3
  save_interval: 1000
  eval_interval: 70000
  feature_dim: 64
  feature_maps: 1
  layer_slice:
    outer_slice: [1, null, 2]  # equivalent to [1::2]
    inner_slice: [0, 1]       # equivalent to [5:10]

logging:
  log_dir: "./logs"
  level: "INFO"
